{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObAaX79Npkj4NhMbgGJq36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vetri-thirumagan-s/langchain_projects/blob/main/resume_shortlisting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ9oLDybxUhS",
        "outputId": "3a304cbb-601b-4daf-af65-490c34978210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai\n",
        "%pip install --quiet pypdf\n",
        "%pip install --quiet langchain\n",
        "%pip install --quiet faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "egWxcN_YyT3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA2CgArkZL3ooEIXP0tC2prK3N73_C00DU\""
      ],
      "metadata": {
        "id": "QEv4SBN_yto7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGoogleGenerativeAI(model=\"gemini-pro\",convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "jmNBzlwGyxwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "vVnacafzy1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/data-analyst-resume-example.pdf\").load()"
      ],
      "metadata": {
        "id": "yBuNkpFBy8bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "Personal Details:Extract all the details about the person What is the name of the person and his mobile number and email id which are identitifies at the beginning of the resume.\\\n",
        "Answer output them as a comma separated Python dictionary.\n",
        "\n",
        "Skills: what are the technical and non technical skills? \\\n",
        "Answer output them as a comma separated Python dictionary.\n",
        "\n",
        "Education: What is the highest education of the candidate and what is the GPA as mentioned in the text?\\\n",
        "Answer Output should be the university/college name and GPA if given in text, output them as a comma separated Python dictionary.\n",
        "\n",
        "Projects: Extract all project titles mentioned in a text\\\n",
        "and output them as a comma separated Python dictionary.\n",
        "\n",
        "Publications: Extract all publication titles mentioned in a text\\\n",
        "and output them as a comma separated Python dictionary.\n",
        "\n",
        "Work experience: Extract all organisation name where he/she has worked along with number of years or months worked there and also extract designation\\\n",
        "and output them as a comma separated Python dictionary.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "\n",
        "Personal Details\n",
        "Skills\n",
        "Education\n",
        "Projects\n",
        "Publications\n",
        "Work experience\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SYBwosY3zR5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "\n",
        "messages = prompt_template.format_messages(text=loader,format_instruction=prompt_template)\n",
        "about=llm.invoke(messages)\n",
        "about"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wpnN5O-zdeC",
        "outputId": "ce0f07ac-4e2f-479f-9f22-cc197c354784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```python\\n{\\n \"Personal Details\": [\\n  \"Vetri Thirumagan S\",\\n  \"+919715506331\",\\n  \"vetrithiru2k4@gmail.com\"\\n ],\\n \"Skills\": [\\n  \"Machine Learning\",\\n  \"Artificial Intelligence\",\\n  \"Chatbots\",\\n  \"English\",\\n  \"Tamil\",\\n  \"Python\",\\n  \"C\",\\n  \"SQL\",\\n  \"TensorFlow\",\\n  \"Keras\",\\n  \"PyTorch\"\\n ],\\n \"Education\": [\\n  \"Sri Sai Ram Engineering College\",\\n  \"8.0\",\\n  \"B. Tech Artificial Intelligence and Data Science\",\\n  \"Sep 2022 - Present\",\\n  \"Rose Mary Matriculation Higher Secondary School\",\\n  \"Class 12th\",\\n  \"86%\",\\n  \"2020\",\\n  \"Rose Mary Matriculation Higher Secondary School\",\\n  \"Class 10th\",\\n  \"94%\",\\n  \"2022\"\\n ],\\n \"Projects\": [],\\n \"Publications\": [],\\n \"Work experience\": []\\n}\\n```')"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(about)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnqWPHP8XAUZ",
        "outputId": "30490098-965c-49ad-b99f-cf9f1f11a58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIMessage(content='```python\\n{\\n \"Personal Details\": [\\n  \"Vetri Thirumagan S\",\\n  \"+919715506331\",\\n  \"vetrithiru2k4@gmail.com\"\\n ],\\n \"Skills\": [\\n  \"Machine Learning\",\\n  \"Artificial Intelligence\",\\n  \"Chatbots\",\\n  \"English\",\\n  \"Tamil\",\\n  \"Python\",\\n  \"C\",\\n  \"SQL\",\\n  \"TensorFlow\",\\n  \"Keras\",\\n  \"PyTorch\"\\n ],\\n \"Education\": [\\n  \"Sri Sai Ram Engineering College\",\\n  \"8.0\",\\n  \"B. Tech Artificial Intelligence and Data Science\",\\n  \"Sep 2022 - Present\",\\n  \"Rose Mary Matriculation Higher Secondary School\",\\n  \"Class 12th\",\\n  \"86%\",\\n  \"2020\",\\n  \"Rose Mary Matriculation Higher Secondary School\",\\n  \"Class 10th\",\\n  \"94%\",\\n  \"2022\"\\n ],\\n \"Projects\": [],\\n \"Publications\": [],\\n \"Work experience\": []\\n}\\n```')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume=[]"
      ],
      "metadata": {
        "id": "l9YvPcAuFxBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resume.append(str(about))\n"
      ],
      "metadata": {
        "id": "nUy_nq4Nzh2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open('myfile.txt', \"w\")\n",
        "file1.writelines(resume)\n",
        "file1.close()"
      ],
      "metadata": {
        "id": "CbYANegh2o8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"myfile.txt\").load()\n",
        "db = FAISS.from_documents(loader,embeddings)\n",
        "retriever = db.as_retriever(score_threshold=0.4)"
      ],
      "metadata": {
        "id": "ExQ5r0JD0xv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"who is vetrithiru2k4@gmail.com\"\n",
        "docs =  retriever.get_relevant_documents(query)\n",
        "docs.\n",
        "# type(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFPbnoF2Dfjw",
        "outputId": "6bb119ef-0364-4c1f-82fd-a116713d3ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='content=\\'```\\\\n{\\\\n \"Personal Details\": [\\\\n  \"Vetri Thirumagan S\",\\\\n  \"+919715506331\",\\\\n  \"vetrithiru2k4@gmail.com\"\\\\n ],\\\\n \"Skills\": [\\\\n  \"Machine Learning\",\\\\n  \"Artificial Intelligence\",\\\\n  \"Chatbots\",\\\\n  \"English\",\\\\n  \"Tamil\",\\\\n  \"Python\",\\\\n  \"C\",\\\\n  \"SQL\",\\\\n  \"TensorFlow\",\\\\n  \"Keras\",\\\\n  \"PyTorch\"\\\\n ],\\\\n \"Education\": [\\\\n  \"Sri Sai Ram Engineering College\",\\\\n  \"8.0\",\\\\n  \"B. Tech Artificial Intelligence and Data Science\",\\\\n  \"Sep 2022 - Present\",\\\\n  \"Rose Mary Matriculation Higher Secondary School\",\\\\n  \"Class 12th\",\\\\n  \"86%\",\\\\n  \"2020\",\\\\n  \"Rose Mary Matriculation Higher Secondary School\",\\\\n  \"Class 10th\",\\\\n  \"94%\",\\\\n  \"2022\"\\\\n ],\\\\n \"Projects\": [],\\\\n \"Publications\": [],\\\\n \"Work experience\": []\\\\n}\\\\n```\\'content=\\'```python\\\\n{\\\\n \"Personal Details\": [\\\\n  \"FARAH \\\\\\\\xa0MARTIN\",\\\\n  \"(123) 456-7890\",\\\\n  \"farahmartin@email.com\",\\\\n  \"Brooklyn, NY\"\\\\n ],\\\\n \"Skills\": [\\\\n  \"SQL\",\\\\n  \"Excel/ Google Sheets\",\\\\n  \"A/B Testing &\\\\\\\\nExperimentation\",\\\\n  \"Tableau\",\\\\n  \"Python (Pandas, Scikit-learn)\",\\\\n  \"Google Analytics\",\\\\n  \"Leadership Experience\"\\\\n ],\\\\n \"Education\": [\\\\n  \"University of Pittsburgh\",\\\\n  \"April 2014\"\\\\n ],\\\\n \"Projects\": [],\\\\n \"Publications\": [],\\\\n \"Work experience\": [\\\\n  \"Data Analyst\\\\\\\\nFountain House\",\\\\n  \"May 2018 - current/New York, NY\",\\\\n  \"Data Analyst\\\\\\\\nWavely\",\\\\n  \"August 2016 - May 2018/New York, NY\",\\\\n  \"Product Modeling Analyst\\\\\\\\nGeico\",\\\\n  \"August 2014 - August 2016/Washington D.C.\"\\\\n ]\\\\n}\\\\n```\\'', metadata={'source': 'myfile.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_5YyHPJQQP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " prompt_template=\"Find who will be best fit for the {job} job?\"\n",
        " PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"job\"])"
      ],
      "metadata": {
        "id": "l7pkSkhx0Bhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",\n",
        "                                        retriever=retriever,\n",
        "                                        input_key=\"query\",\n",
        "                                        return_source_documents=False,\n",
        "                                  )\n",
        "\n",
        "p=qa_chain(\"Find who will be best fit for the data analyst job?\")\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvflZJwq4KE2",
        "outputId": "e418e901-7c50-4f65-8741-f183b61242a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Find who will be best fit for the data analyst job?',\n",
              " 'result': 'I do not have enough information to answer this question.'}"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "HCgnF0jLOWEJ",
        "outputId": "64a118be-371f-4c38-b646-644aed5a2932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. **Educational Background:**\\n\\n   - Master's degree in Data Science, Business Analytics, Statistics, or related field.\\n   - Bachelor's degree in Computer Science, Mathematics, Engineering, or related field with relevant coursework in data analysis and statistics.\\n\\n2. **Technical Skills:**\\n\\n   - Programming languages: Python, R, SQL, and/or Java.\\n   - Data visualization tools: Tableau, Power BI, ggplot2, or similar.\\n   - Statistical analysis software: SPSS, SAS, or similar.\\n   - Cloud computing platforms: AWS, Azure, or Google Cloud.\\n   - Machine learning and artificial intelligence techniques.\\n\\n3. **Analytical and Problem-Solving Skills:**\\n\\n   - Strong analytical and critical thinking skills.\\n   - Ability to identify patterns, trends, and insights from data.\\n   - Expertise in solving complex business problems using data-driven insights.\\n\\n4. **Communication and Presentation Skills:**\\n\\n   - Excellent written and verbal communication skills.\\n   - Ability to present findings and insights clearly and effectively to stakeholders.\\n   - Experience in collaborating with cross-functional teams.\\n\\n5. **Industry Experience:**\\n\\n   - Experience in data analysis, business intelligence, or market research.\\n   - Knowledge of the specific industry or domain the company operates in.\\n\\n6. **Soft Skills:**\\n\\n   - Attention to detail and accuracy.\\n   - Strong work ethic and ability to meet deadlines.\\n   - Team player and ability to collaborate effectively.\\n   - Ability to work independently and as part of a team.\\n\\n7. **Additional Qualifications:**\\n\\n   - Certifications in data analysis, such as the Certified Analytics Professional (CAP) or the Certified Data Scientist (CDS).\\n   - Experience in using data analysis tools and technologies, such as Hadoop, Hive, and Pig.\\n   - Knowledge of data mining and predictive analytics techniques.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warning = \"If you don't know the answer, just say that you don't know, don't try to make up an answer\"\n",
        "job_description = \"MS or PhD in computer science or a related technical field,5+ years of industry work experience. Good sense of product with a focus on shipping user-facing data-driven features, Expertise in Python and Python based ML/DL and Data Science frameworks. \\\n",
        "Excellent coding, analysis, and problem-solving skills. Proven knowledge of data structure and algorithms. \\\n",
        "Familiarity in relevant machine learning frameworks and packages such as Tensorflow, PyTorch and HuggingFace\\\n",
        "Experience working with Product Management and decomposing feature requirements into technical work items to ship products\\\n",
        "Experience with generative AI, knowledge of ML Ops and ML services is a plus. This includes Pinecone, LangChain, Weights and Biases etc. \\\n",
        "Familiarity with deployment technologies such as Docker, Kubernetes and Triton are a plus\\\n",
        "Strong communication and collaboration skills\"\n",
        "question = warning+job_description + \" Based on the given job description\"\n",
        "query = question + \"short list which index of the list is good fit based on skills,education and work experience mwntioned in it? also provide the candidate name which will be mentioned in first line of pdf without subheading and if you don't have access to the list of candidates explain it why \"\n",
        "\n",
        "# query =\"which index of the list is good fit for Data analysis roles based on skills,education and work experience mwntioned in each element of the list?\"\n",
        "\n",
        "llm_response = qa_chain(query)\n",
        "llm_response['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UfVELs3K4bJi",
        "outputId": "c7fe1ad0-b3bc-494f-ea5d-c54947235c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not have access to the list of candidates, so I cannot provide the candidate name or the index of the candidate that is a good fit for the job description.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_eA6z8D74lvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing the csv module\n",
        "import csv\n",
        "\n",
        "# my data rows as dictionary objects\n",
        "mydict=about\n",
        "\n",
        "# field names\n",
        "fields = [\"Personal Details\",\"Skills\",\"Education\",\"Projects\",\"Publications\",\"Work experience\"]\n",
        "\n",
        "# name of csv file\n",
        "filename = \"university_records.csv\"\n",
        "\n",
        "# writing to csv file\n",
        "with open(filename, 'w') as csvfile:\n",
        "    # creating a csv dict writer object\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
        "\n",
        "    # writing headers (field names)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # writing data rows\n",
        "    writer.writerows(mydict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "PdlNlSkITw-5",
        "outputId": "65257ee5-f186-4dd7-b0e6-be654ccc9f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'keys'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-5fb37f0f7805>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# writing data rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/csv.py\u001b[0m in \u001b[0;36mwriterows\u001b[0;34m(self, rowdicts)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# Guard Sniffer's type checking against builds that exclude complex()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/csv.py\u001b[0m in \u001b[0;36m_dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasaction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mwrong_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 raise ValueError(\"dict contains fields not in fieldnames: \"\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the rows data\n",
        "rows = about\n",
        "\n",
        "# Specify the file name\n",
        "filename = 'students_data.csv'\n",
        "\n",
        "# Write the rows data to the CSV file with quotes around each field\n",
        "with open(filename, 'w') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
        "    csvwriter.writerows(rows)"
      ],
      "metadata": {
        "id": "fFZrJmqLT6xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "    json.dump(str(about), outfile,indent=4)"
      ],
      "metadata": {
        "id": "i7i4g8i-WbyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8ns_g_4XiwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}